{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "abbrevs = {\"Abk\": \"Abaknon\", \"Aby\": \"Abyan\", \"Aer\": \"Aeronawtika\", \"Agr\": \"Agrikultura\",\n",
    "           \"Agt\": \"Agta, Aeta, Ayta, Baluga, Ita, Negrito\", \"Agu\": \"Agutayanen\", \"Akl\": \"Aklanon\",\n",
    "           \"AM\": \"Agusanon-Manobo\", \"Ana\": \"Anatomiya\", \"Ant\": \"Antropolohiya\", \"Ata\": \"Ata\", \"Alp\": \"Alipusta\",\n",
    "           \"Apa\": \"Apayaw\", \"Ara\": \"Arabe\", \"Ark\": \"Arkitektura\", \"Asn\": \"Astronomiya\",\n",
    "           \"Ayt-Mbk\": \"Ayta-Magbubukun\", \"Ayt-Mgk\": \"Ayta-Magkunana\", \"Bb\": \"Binibini\", \"Bag\": \"Bagobo\",\n",
    "           \"Baj\": \"Bajaw\", \"Bal\": \"Balangaw\", \"Ban\": \"Bantoanan\", \"Bat\": \"Batas\", \"Bgo\": \"Bago Igorot\",\n",
    "           \"Bik\": \"Bikol\", \"Bil\": \"Bilaan\", \"Bio\": \"Biyolohiya\", \"BioK\": \"Biyokemistri\", \"Bis\": \"Bisaya\",\n",
    "           \"Bon\": \"Bontok\", \"Bot\": \"Botanika\", \"Btk\": \"Batak\", \"Buh\": \"Buhid\", \"Buk\": \"Bukidnon\",\n",
    "           \"Bun\": \"Buntuanon\", \"Cf\": \"confer\", \"Cha\": \"Chabacano\", \"Com\": \"Agham Computer\", \"Cuy\": \"Cuyonen\",\n",
    "           \"Den\": \"Dentistry\", \"Ekl\": \"Ekolohiya\", \"Ekn\": \"Ekonomiks\", \"Ele\": \"Elektrisidad\", \"Esp\": \"Espanyol\",\n",
    "           \"Etn\": \"Etnolohiya\", \"Fil\": \"Filipino\", \"Fre\": \"French\", \"G\": \"Ginoo\", \"Ger\": \"German\",\n",
    "           \"Gra\": \"Gramatika\", \"Gri\": \"Griyego\", \"hal\": \"halimbawa\", \"Han\": \"Hanunuo\", \"Heb\": \"Hebrew\",\n",
    "           \"Heg\": \"Heograpiya\", \"Heo\": \"Heolohiya\", \"Hgn\": \"Higa-onon\", \"Hil\": \"Hiligaynon\", \"Hin\": \"Hindi\",\n",
    "           \"Iba\": \"Ibanag\", \"Iby\": \"Ibaloy\", \"Ifu\": \"Ifugaw\", \"Igo\": \"Igorot\", \"Ilk\": \"Iloko\", \"Ilt\": \"Ilongot\",\n",
    "           \"Ing\": \"Ingles\", \"Inh\": \"Inhenyeriya\", \"Isn\": \"Isneg\", \"Ita\": \"Italian\", \"Itn\": \"Itneg\",\n",
    "           \"Iva\": \"Ivatan\", \"Jap\": \"Japanese\", \"Jr\": \"Junior\", \"JM\": \"Jama Mapun\", \"k\": \"kilo\", \"Kal\": \"Kalinga\",\n",
    "           \"Kan\": \"Kankanaey\", \"kg\": \"kilogramo\", \"Klg\": \"Kalagan\", \"Kap\": \"Kapampangan\", \"Kar\": \"Karpenteriya\",\n",
    "           \"km\": \"kilometro\", \"Krw\": \"Karaw\", \"Kem\": \"Kemistri\", \"Kin\": \"Kinetikang Pantao\", \"Kol\": \"kolokyal\",\n",
    "           \"Kom\": \"Komersiyo\", \"Kor\": \"Koreano\", \"Lat\": \"Latin\", \"Lgw\": \"Lingguwistika\", \"Lit\": \"Literatura\",\n",
    "           \"m\": \"metro\", \"Mag\": \"Maguindanao\", \"Mal\": \"Malay\", \"Man\": \"Mangyan\", \"Mat\": \"Matematika\",\n",
    "           \"Med\": \"Medisina\", \"Mek\": \"Mekanika\", \"Mex\": \"Mexican\", \"Mgn\": \"Mangguangan\", \"Mil\": \"Militar\",\n",
    "           \"Mit\": \"Mitolohiya\", \"mm\": \"milimetro\", \"Mmw\": \"Mamanwa\", \"Mnd\": \"Mandaya\", \"Mnb\": \"Manobo\",\n",
    "           \"Mnb-Agu\": \"Manobo Agusan\", \"Mnb-Cot\": \"Manobo Cotabato\", \"Mns\": \"Mansaka\",\n",
    "           \"MOc\": \"Misamis Occidental\", \"Mrw\": \"Maranaw\", \"Mtl\": \"Metalurhiya\", \"Mtr\": \"Meteorolohiya\",\n",
    "           \"Mus\": \"Musika\", \"n.g.\": \"ng gabi\", \"n.h.\": \"ng hapon\", \"Nor\": \"Norwego\", \"n.u.\": \"ng umaga\",\n",
    "           \"Ntk\": \"Agham Nawtika\", \"Pal\": \"Palawan\", \"Pan\": \"Pangasinan\", \"p\": \"pahina\", \"mp\": \"mga pahina\",\n",
    "           \"pdd\": \"padamdam\", \"Pil\": \"Pilosopiya\", \"Pis\": \"Pisika\", \"Por\": \"Portuguese\", \"pnb\": \"pang-abay\",\n",
    "           \"pnd\": \"pandiwa\", \"png\": \"pangngalan\", \"pnh\": \"panghalip\", \"pnk\": \"pang-angkop\", \"pnu\": \"pang-ukol\",\n",
    "           \"pnr\": \"pang-uri\", \"pnt\": \"pangatnig\", \"pnl\": \"panlapi\", \"Psd\": \"Pangisdaan\", \"ptk\": \"pantukoy\",\n",
    "           \"Rom\": \"Rombloanon\", \"Rus\": \"Ruso\", \"San\": \"Sanskrit\", \"Say\": \"Sayaw\", \"Sld\": \"Sulod\",\n",
    "           \"Seb\": \"Sebwano\", \"Sik\": \"Sikolohiya\", \"Sin\": \"Sining\", \"sm\": \"sentimetro\", \"Sma\": \"Samal\",\n",
    "           \"Snk\": \"Sanskrit\", \"Sos\": \"Sosyolohiya\", \"ST\": \"Sinaunang Tagalog\", \"Sub\": \"Subanon\",\n",
    "           \"Swa\": \"Swahili\", \"Tag\": \"Tagalog\", \"Tbw\": \"Tagbanwa\", \"Tau\": \"Tausug\", \"Tbo\": \"Tiboli\",\n",
    "           \"Teo\": \"Teolohiya\", \"Tgk\": \"Tagakaolo\", \"Tha\": \"Thai\", \"Tib\": \"Tibetan\", \"Tin\": \"Tinggian\",\n",
    "           \"Tir\": \"Tiruray\", \"Tro\": \"Teatro\", \"Tsi\": \"Tsino\", \"Tua-Dus\": \"Tuaran Dusun\", \"Tur\": \"Turkish\",\n",
    "           \"var\": \"varyant\", \"War\": \"Waray\", \"Yak\": \"Yakan\", \"Zam\": \"Zambal\", \"Zoo\": \"Zoolohiya\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A, a (ey) png 1: unang titik sa alpabe-tong Filipino at tinatawag na ey 2: una sa isang serye o kaayusan 3: grado o markang akademiko na na-ngangahulugang pinakamahusay o namumukod 4: pasulát o palimbag na representasyon ng A o a 5: tipo, tulad ng sa printer, upang magawâ ang titik A o a 6: Psl tipo ng dugo ng tao 7: Mus a ikaanim na tono sa eskalang C major o unang tono sa kaugnay na eskalang A minor b ika-anim na tono sa eskalang C major, kilalá bílang la c nakalimbag na no-ta na kumakatawan sa tonong ito d eskala o key na nakabatay sa no-tang ito 8: sukat ng sapatos, higit na maliit sa B  9: cup size ng bra, higit na maliit sa B ngunit higit na malakí sa AA.\n",
      "A, a (a) png: unang titik sa abakadang Tagalog at tinatawag na a.\n",
      "A, (ey) symbol Pis [Ing]: angstrom.\n",
      "A! pdd: bulalas ng alinlangan o paghinto sa sasabihin.\n",
      "-a pnl [Esp]: pambuo ng pangngalan at pang-uri na may kasariang pam-babae, hal niña, maestra Cf  o.\n",
      "a·à png: salitâng batà na nanganga-hulugang dumi, tae, o anumang ma-ruming bagay Cf oò  pnd  mag-a· à, u·ma·à.\n",
      "a·áb png Kar: hugpóng o paghuhug-póng ng dalawang pútol o piraso ng kahoy sa pamamagitan ng bútas at mitsa na kahugis ng buntót ng kalapati Cf hukad, kutab, punit, ukit, utab: hákhak  pnd  a·á·bin, mag-a·áb.\n",
      "a·á·da pnb [Ilk]: nariyán.\n",
      "a·ád·to pnb [War]: naroon.\n",
      "a·a·gáw png Bot: alagáw.\n",
      "CPU times: user 0 ns, sys: 12 ms, total: 12 ms\n",
      "Wall time: 27.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "# step 1, extract all sure words\n",
    "\n",
    "head data/exp/updict/complete_utf.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZYMURGY\n"
     ]
    }
   ],
   "source": [
    "updict = 'data/exp/updict/complete_utf.txt'\n",
    "\n",
    "bufsize = 1048576\n",
    "basedict = {}\n",
    "\n",
    "# step 1\n",
    "with open(updict) as file_in:\n",
    "    while True:\n",
    "        lines = [line.strip() for line in file_in.readlines(bufsize)]\n",
    "        if not lines:\n",
    "            break\n",
    "        for line in lines:\n",
    "            # if true, just plug in\n",
    "            surestart = True\n",
    "            line = re.sub(\"[,!?:\\u0096]\",\" \",line)\n",
    "            line = line.split()\n",
    "            for entry in line:\n",
    "                if surestart:\n",
    "                    surestart = False\n",
    "                elif re.search('[][)(]',entry) or (entry in abbrevs):\n",
    "                    break\n",
    "                entry = entry.upper()\n",
    "                entry = re.sub(\"[ÀÁÂ]\",\"A\", entry)\n",
    "                entry = re.sub(\"[ÉÈÊ]\",\"E\", entry)\n",
    "                entry = re.sub(\"[ÍÎÌ]\",\"I\", entry)\n",
    "                entry = re.sub(\"[ÓÔÒ]\",\"O\", entry)\n",
    "                entry = re.sub(\"[ÚÛÙ]\",\"U\", entry)\n",
    "                entry = re.sub(\"[\\u0091\\u0092]\",\"'\", entry)\n",
    "                entry = re.sub(\"[\\u00ad]\",\"-\", entry)\n",
    "                entry = re.sub(\"[\\u00b7]\",\"\",entry)\n",
    "                if entry and (entry not in basedict):\n",
    "                    basedict[entry] = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88844\n",
      "1923\n"
     ]
    }
   ],
   "source": [
    "updict = 'data/exp/updict/complete_utf.txt'\n",
    "\n",
    "bufsize = 1048576\n",
    "adtldict = {}\n",
    "\n",
    "# step 1\n",
    "with open(updict) as file_in:\n",
    "    while True:\n",
    "        lines = [line.strip() for line in file_in.readlines(bufsize)]\n",
    "        if not lines:\n",
    "            break\n",
    "        for line in lines:\n",
    "            # if true, just plug in\n",
    "            surestart = True\n",
    "            line = line.split()\n",
    "            for entry in line:\n",
    "                if surestart:\n",
    "                    surestart = False\n",
    "                    continue\n",
    "                elif re.search('[][)(]',entry):\n",
    "                    continue\n",
    "                entry = re.sub(\"[,!?:\\u0096]\",\"\",entry)\n",
    "                if entry in abbrevs:\n",
    "                    entry = abbrevs[entry]\n",
    "                \n",
    "                # dash handling\n",
    "                if re.search(\"-\",entry):\n",
    "                    sepent = entry.split('-')\n",
    "                    \n",
    "                \n",
    "                entry = entry.upper()\n",
    "                entry = re.sub(\"[ÀÁÂ]\",\"A\", entry)\n",
    "                entry = re.sub(\"[ÉÈÊ]\",\"E\", entry)\n",
    "                entry = re.sub(\"[ÍÎÌ]\",\"I\", entry)\n",
    "                entry = re.sub(\"[ÓÔÒ]\",\"O\", entry)\n",
    "                entry = re.sub(\"[ÚÛÙ]\",\"U\", entry)\n",
    "                entry = re.sub(\"[\\u0091\\u0092]\",\"'\", entry)\n",
    "                entry = re.sub(\"[\\u00ad]\",\"-\", entry)\n",
    "                entry = re.sub(\"[\\u00b7\\u0093\\u0094\\u0097]\",\"\",entry)\n",
    "                entry = re.sub(\"^[0-9.]*$\",\"\",entry)\n",
    "                entry = re.sub(\"^([A-ZÑ]{3,})[0-9]$\",\"\\1\",entry)\n",
    "                entry = re.sub(\"^([A-ZÑ]*)[0-9][0-9ABC]?[\\.;]$\",\"\\1\",entry)\n",
    "                entry = re.sub(\"^([A-ZÑ]*)[\\.;]$\",\"\\1\",entry)\n",
    "                if entry:\n",
    "                    if re.search(\"^[A-Z'\\'']*$\", entry) and (entry not in basedict):\n",
    "                        basedict[entry] = ''\n",
    "                    elif re.search(\"^[A-Z'\\'']+-[A-Z'\\''-]*$\", entry) and (entry not in basedict) and (entry not in adtldict):\n",
    "                        adtldict[entry] = ''\n",
    "\n",
    "# step 2: filtering round\n",
    "todelete = []\n",
    "for token in adtldict:\n",
    "    \n",
    "    remsplit = re.sub(\"-\",\"\",token)\n",
    "    if remsplit in basedict:\n",
    "        todelete.append(token)\n",
    "    \n",
    "    # process two-word splits\n",
    "    splitoken = token.split('-')\n",
    "    if len(splitoken) == 2:\n",
    "        # case of word repetition\n",
    "        if splitoken[0] == splitoken[1]:\n",
    "            if token not in basedict:\n",
    "                basedict[token] = ''\n",
    "            if token not in todelete:\n",
    "                todelete.append(token)\n",
    "        # case where both words are already in basedict\n",
    "        elif (splitoken[0] in basedict) and (splitoken[1] in basedict):\n",
    "            if token not in basedict:\n",
    "                basedict[token] = ''\n",
    "            if token not in todelete:\n",
    "                todelete.append(token)\n",
    "        #case of suffix+word-word where word is 4 letters or more\n",
    "        elif (splitoken[1] in splitoken[0]) and (len(splitoken[1]) >= 4):\n",
    "            basedict[token] = ''\n",
    "            if token not in todelete:\n",
    "                todelete.append(token)\n",
    "                \n",
    "                \n",
    "for token in todelete:\n",
    "    del(adtldict[token])\n",
    "\n",
    "keys = list(basedict.keys())\n",
    "print(len(keys))\n",
    "\n",
    "file_out = open('data/exp/updict/updict_vocabs', 'w')\n",
    "for token in sorted(keys):\n",
    "    file_out.write(\"%s\\n\" % token)\n",
    "file_out.close()\n",
    "\n",
    "\n",
    "keys = list(adtldict.keys())\n",
    "print(len(keys))\n",
    "\n",
    "file_out = open('data/exp/updict/updict_vocabs_addtl', 'w')\n",
    "for token in sorted(keys):\n",
    "    file_out.write(\"%s\\n\" % token)\n",
    "file_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "'DAY.\n",
      "'EKA.\n",
      "+\n",
      "+AN\n",
      "+AN+NA\n",
      "+AN+NG\n",
      "+BX\n",
      "+ESP\n",
      "+HAN+NG\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat data/exp/updict/updict_vocabs_addtl | grep -v '^[0-9A-ZÑ'\\'']*$' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrevs = {'png':'pang·nga·lan'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_dict(entry, extracts):\n",
    "    entry = entry.split()\n",
    "    \n",
    "    # normalize first\n",
    "    for idx, token in enumerate(entry):\n",
    "        if token in abbrevs:\n",
    "            entry[idx] = abbrevs[token]\n",
    "    \n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updict = 'data/exp/updict/complete_utf.txt'\n",
    "\n",
    "bufsize = 1048576\n",
    "basedict = {}\n",
    "\n",
    "# step 1, \n",
    "with open(updict) as file_in:\n",
    "    while True:\n",
    "        lines = [line.strip() for line in file_in.readlines(bufsize)]\n",
    "        if not lines:\n",
    "            break\n",
    "        for line in lines:\n",
    "            basedict = parse_dict(line, basedict)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
